\chapter{GPU Databases}
Related to the massive amount of data that is collected nowadays, the stagnation of CPU speed
and the trend to use the GPU for tasks like machine learning, the database developers have discovered the GPU to improve the performance of their products, too.
Hence the main idea of GPU databases is to perform some operations on the GPU for acceleration purposes.

\paragraph{Strengths}
GPUs do have their strengths on parallelable tasks.
This is due to the fact that GPUs can have thousands of cores and high bandwidth memory on each card.
Thus most of the GPU databases products focus on analytics.


\paragraph{Weaknesses} Beside of these strengths, GPU databases host several pitfalls like transfer of the data from the CPU to the GPU,
 the memory limitations and the massiv costs of GPU servers.


\section{Components of a GPU database}
The current section will give you an overview of the components a GPU database consists of.
The paper \cite{bress2014gpu} of Sebastian Bress et al. does split the components into Functional and Non-Functional properties.
Since those categories are reasonable they are used in this paper as well.
The next sub section will explain and list these properties.

\subsection{Non-Functional properties}

\subsubsection{Performance}
Performance is the biggest advantage of GPU database, but not all tasks are automatic faster on GPUs.
Due to the huge amount of processors tasks that are able to parallelise easily are incredibly fast.
Unfortunately task which require a complex control flow or are hard to parallelise don't profit from the cores.
And there is always the bottleneck of the data transfer to the GPU.

\subsubsection{Portability}
In terms of portability we talk about if the GPU database is able to run on different GPUs or CPUs vendors/architectures, like NVIDIA or AMD graphic cards.
Often this requirement is in contrast to the performance property, since the vendors offer special implementation or hardware details to accelerate their products.

\subsubsection{Scalability}
To my point of view the paper \cite{bress2014gpu} of Sebastian Bress et al. missed the important criteria of the scalability.
The collected data of companies grow and grow, thus you need to have memory for all that data. Sadly the memory of GPUs is often limited,
hence the only way to handle this issue it to scale your GPU database verticaly over multiple GPUs.

\subsection{Functional properties}

\subsubsection{Storage system}
If we talk about storage systems there are several scenarios conceivable.
First with the Video Random Access Memory (VRAM) of the GPUs we have an additional storage medium next to the Random-Access Memory (RAM) and the hard disk.
The different mediums provide different advantages and disadvantages.
Hard disks are persistent, cheap and have a huge capacity.
Unfortunately they are pretty slow.
Random-Access Memory is very fast compared to hard disks but the transfer to the GPU is still a bottleneck and it isn't a persistent storage, either.
With Video Random Access Memory the bottleneck of the transfer disappears, but most of the time the storage capacity is highly limited.

\subsubsection{Storage model}
In terms of storage model, there are row stores or column stores \cite{abadi2008column}.
Row stores store table records in a sequence of rows.
Column stores store table records in a sequence of columns, the entries of a column is stored in contiguous memory locations \cite{bress2014design}.
The advantages of column stores are tasks like aggregations, though row stores are more efficient if the result of a query returns multiple rows.


\subsubsection{Processing model}
There are two processing models in modern databases tuple-at-a-time and operator-at-a-time.
The tuple-at-a-time is similar to an iterator, which iterates over the relevant tuples and applies the operations.
The operator-at-a-time fits to GPUs, since it applies the same operation on a bulk of data.

\subsubsection{Query processing}
GPU database systems are able to use the GPU and the CPU, hence it is necessary to choose the right processor for the right task.
\paragraph{Query placement} It is a extremely difficult task to decide which processing device is the most accurate for the current query.
\paragraph{Optimization} To optimize the performance in therms of query execution time, several factors are include.
For example the operations, the data, hardware specifications and even more.

\subsubsection{Transaction support}
An other problem are transactions and consistency on GPUs, until now there is almost no research done in this area.
Thus most of the GPU database don't support transactions.


\subsection{Proposed architecture}
The paper \cite{bress2014gpu} proposes an architecture with an in-memory storage, using a column store, an operator-at-a-time processing model, cross device processing and no transaction support.
With regard to the portability a hardware oblivious architecture is suggested.
To my point of view a hardware aware GPU database would make more sense.
Since GPU databases are all about speed, use hardware specific tuning would result in more acceleration.
And the huge amount of data makes scalability absolutely necessary.